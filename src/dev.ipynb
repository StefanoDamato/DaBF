{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_tensor = torchvision.transforms.ToTensor()\n",
    "tensor_to_image = torchvision.transforms.ToPILImage()\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST('../data/', train= True, transform=image_to_tensor, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST('../data/', train= False, transform=image_to_tensor, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(mnist_train) == 60000\n",
    "assert len(mnist_test) == 10000\n",
    "figure, label = mnist_train[0]\n",
    "D = figure.numel()\n",
    "assert D == 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, D, nlayers =8):\n",
    "        super(FeedForward, self).__init__()\n",
    "        assert type(D) == int\n",
    "        assert type(nlayers) == int\n",
    "        self.D = D\n",
    "        self.nlayers = nlayers\n",
    "        self.first = nn.Linear(D+1, D)\n",
    "        self.linears = nn.ModuleList([nn.Linear(D, D) for i in range(nlayers-1)])\n",
    "        \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = torch.cat((x, t.reshape(-1, 1)), axis=1)\n",
    "        x = self.first(x)\n",
    "        for lin in self.linears:\n",
    "            x = torch.clamp(lin(F.relu(x)), min=0., max=1.)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "class Diffusion():\n",
    "    def __init__(self, T, D, betas = 0.01):\n",
    "        assert type(T) == int\n",
    "        self.T = T\n",
    "        self.betas = betas = torch.tensor(0.5).repeat(T) if type(betas) == float else betas\n",
    "        self.alphas = 1-self.betas\n",
    "        self.alphas_hat = torch.cumprod(self.alphas, axis=0)\n",
    "        self.mvn = torch.distributions.MultivariateNormal(torch.zeros(D), torch.eye(D))\n",
    "        \n",
    "\n",
    "    def sample_t(self, B, all_equal = True):\n",
    "        if all_equal:\n",
    "            t = torch.randint(0, self.T, torch.Size([1])).repeat(B)\n",
    "        else:\n",
    "            t = torch.randint(0, self.T, torch.Size([B]))\n",
    "        return t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "loss_hist = []\n",
    "\n",
    "diff = Diffusion(T = 200, D = D, betas = torch.linspace(1e-04, 0.02, 200))\n",
    "eps_theta = FeedForward(D)\n",
    "\n",
    "optimizer = torch.optim.Adam(eps_theta.parameters(), lr = 1e-03)\n",
    "L2_loss = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t loss: 47010550.69921875\n",
      "epoch: 1 \t loss: 46955217.61328125\n",
      "epoch: 2 \t loss: 46929584.890625\n",
      "epoch: 3 \t loss: 46903828.900390625\n",
      "epoch: 4 \t loss: 46885236.080078125\n",
      "epoch: 5 \t loss: 46887525.328125\n",
      "epoch: 6 \t loss: 46873618.0859375\n",
      "epoch: 7 \t loss: 46850020.08203125\n",
      "epoch: 8 \t loss: 46838223.017578125\n",
      "epoch: 9 \t loss: 46840237.521484375\n",
      "epoch: 10 \t loss: 46832952.642578125\n",
      "epoch: 11 \t loss: 46831529.24609375\n",
      "epoch: 12 \t loss: 46831905.294921875\n",
      "epoch: 13 \t loss: 46813189.1875\n",
      "epoch: 14 \t loss: 46800065.53125\n",
      "epoch: 15 \t loss: 46806977.55078125\n",
      "epoch: 16 \t loss: 46804328.1640625\n",
      "epoch: 17 \t loss: 46797081.08984375\n",
      "epoch: 18 \t loss: 46801228.59375\n",
      "epoch: 19 \t loss: 46775368.7421875\n",
      "epoch: 20 \t loss: 46756717.56640625\n",
      "epoch: 21 \t loss: 46749003.36328125\n",
      "epoch: 22 \t loss: 46756823.021484375\n",
      "epoch: 23 \t loss: 46753701.275390625\n",
      "epoch: 24 \t loss: 46762081.12109375\n",
      "epoch: 25 \t loss: 46745911.037109375\n",
      "epoch: 26 \t loss: 46750144.5546875\n",
      "epoch: 27 \t loss: 46749096.53125\n",
      "epoch: 28 \t loss: 46737230.091796875\n",
      "epoch: 29 \t loss: 46725130.330078125\n",
      "epoch: 30 \t loss: 46745776.22265625\n",
      "epoch: 31 \t loss: 46727806.978515625\n",
      "epoch: 32 \t loss: 46724312.28515625\n",
      "epoch: 33 \t loss: 46729893.171875\n",
      "epoch: 34 \t loss: 46734636.6875\n",
      "epoch: 35 \t loss: 46730231.962890625\n",
      "epoch: 36 \t loss: 46719181.158203125\n",
      "epoch: 37 \t loss: 46727109.173828125\n",
      "epoch: 38 \t loss: 46712664.796875\n",
      "epoch: 39 \t loss: 46726309.970703125\n",
      "epoch: 40 \t loss: 46727104.232421875\n",
      "epoch: 41 \t loss: 46708802.970703125\n",
      "epoch: 42 \t loss: 46711911.80859375\n",
      "epoch: 43 \t loss: 46718599.59765625\n",
      "epoch: 44 \t loss: 46705786.3984375\n",
      "epoch: 45 \t loss: 46688456.18359375\n",
      "epoch: 46 \t loss: 46705073.021484375\n",
      "epoch: 47 \t loss: 46698895.572265625\n",
      "epoch: 48 \t loss: 46694961.380859375\n",
      "epoch: 49 \t loss: 46698790.271484375\n",
      "epoch: 50 \t loss: 46699214.0546875\n",
      "epoch: 51 \t loss: 46693557.19140625\n",
      "epoch: 52 \t loss: 46685961.4921875\n",
      "epoch: 53 \t loss: 46685797.78515625\n",
      "epoch: 54 \t loss: 46712858.623046875\n",
      "epoch: 55 \t loss: 46688338.861328125\n",
      "epoch: 56 \t loss: 46669863.97265625\n",
      "epoch: 57 \t loss: 46675217.455078125\n",
      "epoch: 58 \t loss: 46676633.6953125\n",
      "epoch: 59 \t loss: 46672362.083984375\n",
      "epoch: 60 \t loss: 46674454.32421875\n",
      "epoch: 61 \t loss: 46672477.1484375\n",
      "epoch: 62 \t loss: 46678200.2421875\n",
      "epoch: 63 \t loss: 46676586.951171875\n",
      "epoch: 64 \t loss: 46689363.193359375\n",
      "epoch: 65 \t loss: 46683601.71875\n",
      "epoch: 66 \t loss: 46671894.861328125\n",
      "epoch: 67 \t loss: 46669921.64453125\n",
      "epoch: 68 \t loss: 46692101.408203125\n",
      "epoch: 69 \t loss: 46656649.890625\n",
      "epoch: 70 \t loss: 46667831.37109375\n",
      "epoch: 71 \t loss: 46662962.34765625\n",
      "epoch: 72 \t loss: 46686470.03125\n",
      "epoch: 73 \t loss: 46667344.087890625\n",
      "epoch: 74 \t loss: 46669920.458984375\n",
      "epoch: 75 \t loss: 46667328.630859375\n",
      "epoch: 76 \t loss: 46662298.197265625\n",
      "epoch: 77 \t loss: 46670685.26171875\n",
      "epoch: 78 \t loss: 46673625.865234375\n",
      "epoch: 79 \t loss: 46674380.958984375\n",
      "epoch: 80 \t loss: 46679062.767578125\n",
      "epoch: 81 \t loss: 46650037.228515625\n",
      "epoch: 82 \t loss: 46660959.63671875\n",
      "epoch: 83 \t loss: 46673238.078125\n",
      "epoch: 84 \t loss: 46658260.84375\n",
      "epoch: 85 \t loss: 46673667.59765625\n",
      "epoch: 86 \t loss: 46662676.689453125\n",
      "epoch: 87 \t loss: 46669197.013671875\n",
      "epoch: 88 \t loss: 46665542.41796875\n",
      "epoch: 89 \t loss: 46666956.865234375\n",
      "epoch: 90 \t loss: 46664352.01953125\n",
      "epoch: 91 \t loss: 46665500.4375\n",
      "epoch: 92 \t loss: 46655972.4453125\n",
      "epoch: 93 \t loss: 46657149.31640625\n",
      "epoch: 94 \t loss: 46658726.509765625\n",
      "epoch: 95 \t loss: 46656722.658203125\n",
      "epoch: 96 \t loss: 46648750.5\n",
      "epoch: 97 \t loss: 46648320.55859375\n",
      "epoch: 98 \t loss: 46667581.986328125\n",
      "epoch: 99 \t loss: 46634839.853515625\n",
      "epoch: 100 \t loss: 46654992.169921875\n",
      "epoch: 101 \t loss: 46659059.734375\n",
      "epoch: 102 \t loss: 46649666.8828125\n",
      "epoch: 103 \t loss: 46645290.708984375\n",
      "epoch: 104 \t loss: 46654931.9765625\n",
      "epoch: 105 \t loss: 46646745.9453125\n",
      "epoch: 106 \t loss: 46647642.36328125\n",
      "epoch: 107 \t loss: 46650950.166015625\n",
      "epoch: 108 \t loss: 46656268.98828125\n",
      "epoch: 109 \t loss: 46657366.4453125\n",
      "epoch: 110 \t loss: 46654934.84375\n",
      "epoch: 111 \t loss: 46650179.619140625\n",
      "epoch: 112 \t loss: 46666656.10546875\n",
      "epoch: 113 \t loss: 46658353.0546875\n",
      "epoch: 114 \t loss: 46648661.0234375\n",
      "epoch: 115 \t loss: 46677163.48828125\n",
      "epoch: 116 \t loss: 46664909.44140625\n",
      "epoch: 117 \t loss: 46663389.61328125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m t \u001b[39m=\u001b[39m diff\u001b[39m.\u001b[39msample_t(B, all_equal\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m alphas_hat_array \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_to(diff\u001b[39m.\u001b[39malphas_hat[t]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), (B, D))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m x \u001b[39m=\u001b[39m x0\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39msqrt(alphas_hat_array) \u001b[39m+\u001b[39m eps\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39;49msqrt(\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49malphas_hat_array)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m eps_pred  \u001b[39m=\u001b[39m eps_theta(x, t\u001b[39m/\u001b[39mdiff\u001b[39m.\u001b[39mT)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stefano.damato/Codebase/DaBF/src/dev.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m L2_loss(eps, eps_pred)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, _ in trainloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        B = images.shape[0]\n",
    "        eps = diff.mvn.sample(torch.Size([B]))\n",
    "\n",
    "        x0 = torch.flatten(images, start_dim = 1)\n",
    "        t = diff.sample_t(B, all_equal=False)\n",
    "\n",
    "        alphas_hat_array = torch.broadcast_to(diff.alphas_hat[t].reshape(-1, 1), (B, D))\n",
    "        x = x0*torch.sqrt(alphas_hat_array) + eps*torch.sqrt(1-alphas_hat_array)\n",
    "\n",
    "        eps_pred  = eps_theta(x, t/diff.T)\n",
    "        loss = L2_loss(eps, eps_pred)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'epoch: {epoch} \\t loss: {epoch_loss}')\n",
    "    loss_hist.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = images[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) torch.Size([16, 28, 28]) torch.Size([16, 28, 28])\n",
      "torch.Size([16, 14, 14]) torch.Size([32, 14, 14]) torch.Size([32, 14, 14])\n",
      "torch.Size([32, 7, 7]) torch.Size([64, 7, 7]) torch.Size([64, 7, 7])\n",
      "torch.Size([64, 14, 14]) torch.Size([32, 14, 14]) torch.Size([32, 14, 14])\n",
      "torch.Size([32, 28, 28]) torch.Size([16, 28, 28]) torch.Size([16, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "conv_11 = nn.Conv2d(in_channels=1, out_channels= 16, kernel_size=3, padding=1)\n",
    "conv_12 = nn.Conv2d(in_channels=16, out_channels= 16, kernel_size=3, padding=1)\n",
    "\n",
    "mp = nn.MaxPool2d(kernel_size = (2,2), stride= 2)\n",
    "\n",
    "conv_21 = nn.Conv2d(in_channels=16, out_channels= 32, kernel_size=3, padding=1)\n",
    "conv_22 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=3, padding=1)\n",
    "\n",
    "conv_31 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "conv_32 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "upconv_1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2) \n",
    "\n",
    "conv_41 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "conv_42 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "upconv_2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2) \n",
    "\n",
    "conv_51 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "conv_52 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "\n",
    "conv_out = nn.Conv2d(in_channels=16, out_channels=1, kernel_size=1)\n",
    "\n",
    "mp = nn.MaxPool2d(kernel_size=2, stride= 2)\n",
    "\n",
    "x_11 = img\n",
    "x_12 = conv_11(x_11)\n",
    "x_13 = conv_12(x_12)\n",
    "\n",
    "print(x_11.shape, x_12.shape, x_13.shape)\n",
    "\n",
    "x_21 = mp(x_13)\n",
    "x_22 = conv_21(x_21)\n",
    "x_23 = conv_22(x_22)\n",
    "\n",
    "print(x_21.shape, x_22.shape, x_23.shape)\n",
    "\n",
    "x_31 = mp(x_23)\n",
    "x_32 = conv_31(x_31)\n",
    "x_33 = conv_32(x_32)\n",
    "\n",
    "print(x_31.shape, x_32.shape, x_33.shape)\n",
    "\n",
    "x_41 = upconv_1(x_33)\n",
    "x_42 = conv_41(x_41)\n",
    "x_43 = conv_42(x_42)\n",
    "\n",
    "print(x_41.shape, x_42.shape, x_43.shape)\n",
    "\n",
    "x_51 = upconv_2(x_43)\n",
    "x_52 = conv_51(x_51)\n",
    "x_53 = conv_52(x_52)\n",
    "\n",
    "print(x_51.shape, x_52.shape, x_53.shape)\n",
    "\n",
    "x_out = conv_out(x_53)\n",
    "\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, out_channels, out_fig_side):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        assert type(out_fig_side) == int and type(out_channels) == int\n",
    "        self.out_square_side = out_fig_side\n",
    "        self.out_channels = out_channels\n",
    "        self.linear = nn.Linear(in_features=1, out_features=self.out_channels*(out_fig_side**2))\n",
    "        self.dropout == nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.linear(x)).view(-1, self.out_channels, self.out_square_side, self.out_square_side)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class Conv2Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Conv2Block, self).__init__()\n",
    "        assert type(in_channels) == int and type(out_channels) == int\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=self.in_channels, out_channels= self.out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=self.out_channels, out_channels= self.out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv2d_1(x))\n",
    "        x = F.relu(self.conv2d_2(x))\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.conv_11 = nn.Conv2d(in_channels=1, out_channels= 16, kernel_size=3, padding=1)\n",
    "        self.conv_12 = nn.Conv2d(in_channels=16, out_channels= 16, kernel_size=3, padding=1)\n",
    "\n",
    "        self.mp = nn.MaxPool2d(kernel_size=2, stride= 2)\n",
    "\n",
    "        self.conv_21 = nn.Conv2d(in_channels=16, out_channels= 32, kernel_size=3, padding=1)\n",
    "        self.conv_22 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv_31 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv_32 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv_1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv_41 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv_42 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv_2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv_51 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv_52 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv_out = nn.Conv2d(in_channels=16, out_channels=1, kernel_size=1)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timemb = TimeEmbedding(16, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_11 = nn.Conv2d(in_channels=1, out_channels= 16, kernel_size=3)\n",
    "conv_12 = nn.Conv2d(in_channels=16, out_channels= 16, kernel_size=3)\n",
    "\n",
    "conv_21 = nn.Conv2d(in_channels=16, out_channels= 32, kernel_size=3)\n",
    "conv_22 = nn.Conv2d(in_channels=32, out_channels= 32, kernel_size=3)\n",
    "\n",
    "upconv_1 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2) \n",
    "\n",
    "conv_31 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3)\n",
    "conv_32 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n",
    "\n",
    "mp = nn.MaxPool2d(kernel_size = (2,2), stride= 2)\n",
    "\n",
    "x_11 = img\n",
    "x_12 = conv_11(x_11)\n",
    "x_13 = conv_12(x_12)\n",
    "\n",
    "print(x_11.shape, x_12.shape, x_13.shape)\n",
    "\n",
    "x_21 = mp(x_13)\n",
    "x_22 = conv_21(x_21)\n",
    "x_23 = conv_22(x_22)\n",
    "\n",
    "print(x_21.shape, x_22.shape, x_23.shape)\n",
    "\n",
    "x_31 = upconv_1(x_23)\n",
    "x_32 = conv_31(x_31)\n",
    "x_33 = conv_32(x_32)\n",
    "\n",
    "print(x_31.shape, x_32.shape, x_33.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dabf",
   "language": "python",
   "name": "dabf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
